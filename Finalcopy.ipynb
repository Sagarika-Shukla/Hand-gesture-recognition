{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "Gesture Recognition\n",
    "In this project, you are going to build a 3D Conv models and Conv2D+LSTM/GRU models that will be able to predict the 5 gestures correctly. Please import the following libraries to get started.\n",
    "\n",
    "Problem Statement\n",
    "Imagine you are working as a data scientist at a home electronics company which manufactures state of the art smart televisions. You want to develop a cool feature in the smart-TV that can recognise five different gestures performed by the user which will help users control the TV without using a remote.\n",
    "\n",
    "The gestures are continuously monitored by the webcam mounted on the TV. Each gesture corresponds to a specific command:\n",
    "\n",
    "Thumbs up: Increase the volume\n",
    "\n",
    "Thumbs down: Decrease the volume\n",
    "\n",
    "Left swipe: 'Jump' backwards 10 seconds\n",
    "\n",
    "Right swipe: 'Jump' forward 10 seconds\n",
    "\n",
    "Stop: Pause the movie\n",
    "\n",
    "Understanding the Dataset\n",
    "The training data consists of a few hundred videos categorised into one of the five classes. Each video (typically 2-3 seconds long) is divided into a sequence of 30 frames(images). These videos have been recorded by various people performing one of the five gestures in front of a webcam - similar to what the smart TV will use.\n",
    "\n",
    "Note that all images in a particular video subfolder have the same dimensions but different videos may have different dimensions. Specifically, videos have two types of dimensions - either 360x360 or 120x160 (depending on the webcam used to record the videos). Hence, you will need to do some pre-processing to standardise the videos.\n",
    "\n",
    "Each row of the CSV file represents one video and contains three main pieces of information - the name of the subfolder containing the 30 images of the video, the name of the gesture and the numeric label (between 0-4) of the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc.pilutil import imread, imresize\n",
    "import datetime\n",
    "import os\n",
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-66a52f512011>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mrn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED']=\"30\"\n",
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(30)\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and validatiaon data creator with ablation\n",
    "# when ablation is 10, then 10 folders for each label will be selected.\n",
    "def get_data(path, ablation=None):\n",
    "    train_doc = np.random.permutation(open(path+'train.csv').readlines())\n",
    "    val_doc = np.random.permutation(open(path+'val.csv').readlines())\n",
    "    counts = np.zeros(5) # count for loading folders for 5 classes\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "    # when ablation is None pass full training and val data\n",
    "    if ablation is not None:\n",
    "        # iterating train doc\n",
    "        for doc in train_doc:\n",
    "            lable = int(doc.strip().split(';')[2])\n",
    "            if counts[lable] < ablation:\n",
    "                train_data.append(doc)\n",
    "                counts[lable] += 1 \n",
    "        counts = np.zeros(5)\n",
    "        # iterating val doc\n",
    "        for doc in val_doc:\n",
    "            lable = int(doc.strip().split(';')[2])\n",
    "            if counts[lable] < ablation:\n",
    "                val_data.append(doc)\n",
    "                counts[lable] += 1\n",
    "    else:\n",
    "        train_data, val_data = train_doc, val_doc\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc, val_doc = get_data('Project_data/', ablation=None)\n",
    "batch_size = 32 # experiment with the batch size\n",
    "enable_augmentation = False # augmentation of Data\n",
    "# sequence ids\n",
    "# selecting alternate frames from 7 to 26.\n",
    "seq_idx = range(7,26,2)\n",
    "# image dimensions\n",
    "dim_x, dim_y = 120, 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with img_idx, y,z and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator with augmentation for train data\n",
    "def generator(source_path, folder_list, batch_size, is_train = False, augmention = False, debug=False):\n",
    "    # print('\\nSource path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = seq_idx #create a list of image numbers you want to use for a particular video\n",
    "    x = len(img_idx)\n",
    "    y, z = dim_x, dim_y\n",
    "    while True:\n",
    "        # doubling the data for augmentation\n",
    "        if is_train and augmention:\n",
    "            t = np.concatenate((np.random.permutation(folder_list), np.random.permutation(folder_list)))\n",
    "        else:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            \n",
    "        if (len(t)%batch_size) == 0:\n",
    "            num_batches = int(len(t)/batch_size)\n",
    "        else:\n",
    "            num_batches = len(t)//batch_size + 1\n",
    "            \n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                if debug:\n",
    "                    plt.figure(figsize=(20,5))\n",
    "                #handling remaining datapoints\n",
    "                folder_idx = folder + (batch*batch_size)\n",
    "                if folder_idx >= len(t):\n",
    "                    break\n",
    "                folder_str = t[folder_idx]\n",
    "                imgs = os.listdir(source_path+'/'+ folder_str.split(';')[0]) # read all the images in the folder\n",
    "                # randomly enabling augmentation and augmentation type\n",
    "                aug_type = None\n",
    "                if is_train and augmention and rn.randint(0,1) == 1:\n",
    "                    aug_type = rn.randint(0, 4) #randomly selecting augmentation type\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ folder_str.strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "\n",
    "                    # plotting original images for debugging purpose only\n",
    "                    if debug:\n",
    "                        plt.subplot(2, x, idx+1)\n",
    "                        plt.imshow(image.astype('uint8'))\n",
    "\n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    # making the rectangle images into square by cropping sides\n",
    "                    # so the aspect ration can be mantained while resizing.\n",
    "                    if image.shape[1] > image.shape[0]:\n",
    "                        diff_px = image.shape[1] - image.shape[0]\n",
    "                        crop_start = diff_px//2\n",
    "                        crop_end = crop_start + image.shape[0]\n",
    "                        image = image[:, crop_start:crop_end]\n",
    "                    elif image.shape[0] > image.shape[1]:\n",
    "                        diff_px = image.shape[0] - image.shape[1]\n",
    "                        crop_start = diff_px//2\n",
    "                        crop_end = crop_start + image.shape[1]\n",
    "                        image = image[:, crop_start:crop_end]\n",
    "\n",
    "                    resized_im = imresize(image, size=(y,z))\n",
    "\n",
    "                    if aug_type is not None:\n",
    "                        if aug_type == 0: # edge Enhancement\n",
    "                            resized_im = np.array(Image.fromarray(resized_im, 'RGB').filter(ImageFilter.EDGE_ENHANCE))\n",
    "                        elif aug_type == 1: # adding gaussian blur\n",
    "                            resized_im = np.array(Image.fromarray(resized_im, 'RGB').filter(ImageFilter.GaussianBlur(1)))\n",
    "                        elif aug_type == 2: # enchancing image detailing\n",
    "                            resized_im = np.array(Image.fromarray(resized_im, 'RGB').filter(ImageFilter.DETAIL))\n",
    "                        elif aug_type == 3: # sharpening image\n",
    "                            resized_im = np.array(Image.fromarray(resized_im, 'RGB').filter(ImageFilter.SHARPEN))\n",
    "                        elif aug_type == 4: # Brightness enhancement\n",
    "                            resized_im = np.array(ImageEnhance.Brightness((Image.fromarray(resized_im, 'RGB'))).enhance(1.5))\n",
    "                    # plotting rezised images for debugging purpose only\n",
    "                    if debug:\n",
    "                        plt.subplot(2, x, idx+x+1)\n",
    "                        plt.imshow(resized_im)\n",
    "\n",
    "                    batch_data[folder,idx,:,:,0] = resized_im[:,:,0]/255 #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,1] = resized_im[:,:,1]/255 #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = resized_im[:,:,2]/255 #normalise and feed in the image\n",
    "\n",
    "                batch_labels[folder, int(folder_str.strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = 'Project_data/train' #'/notebooks/storage/Final_data/Collated_training/train'\n",
    "val_path =  'Project_data/val' #'/notebooks/storage/Final_data/Collated_training/val'\n",
    "\n",
    "#multiply number train seq by 2 when using augmentation\n",
    "multiplier = 1\n",
    "if enable_augmentation:\n",
    "    multiplier = 2\n",
    "num_train_sequences = len(train_doc)*multiplier\n",
    "print('# training sequences =', num_train_sequences)\n",
    "\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "\n",
    "num_epochs = 50 # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing generative \n",
    "test_gen = generator(train_path, train_doc, 1, is_train = True, augmention = True, debug = True)\n",
    "d = next(test_gen)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "#### Here you make the model using different functionalities that Keras provides. Remember to use Conv3D and MaxPooling3D and not Conv2D and Maxpooling2D for a 3D convolution model. You would want to use TimeDistributed while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Bidirectional, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D, GlobalAveragePooling3D, ConvLSTM2D\n",
    "from keras.layers.convolutional import Conv2D, Conv3D, MaxPooling2D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "\n",
    "#input shape for the st layer\n",
    "input_shape = (len(seq_idx), dim_x, dim_y, 3)\n",
    "np.random.seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment - 1 Conv3d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "# model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(256, kernel_size=(3, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(3, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(512, kernel_size=(3, 3, 3), activation='relu'))\n",
    "# model.add(Conv3D(512, kernel_size=(3, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expermiment - 2 Reduce the kernerl size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "# model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "# model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expermiment - 3 & 4 batch normalisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "# model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment - 5 & 6 (Increasing epochs to 50 and increase dropout values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "# model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# #model.add(Dropout(0.2))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# #model.add(Dropout(0.2))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# #model.add(Dropout(0.2))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(Conv3D(512, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# #model.add(Dropout(0.2))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment - 7 reduce complexity by reducing 0.2 dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "# model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment - 8 average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss: 0.1388 - categorical_accuracy: 0.9539 - val_loss: 0.1661 - val_categorical_accuracy: 0.9297\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv3D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "# model.add(Conv3D(64, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Conv3D(128, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Conv3D(256, kernel_size=(1, 3, 3), activation='relu'))\n",
    "# model.add(MaxPooling3D(pool_size=(1, 2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(GlobalAveragePooling3D())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment - 9 GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(TimeDistributed(\n",
    "#     Conv2D(32, (3,3), activation='relu'), input_shape=input_shape)\n",
    "# )\n",
    "# model.add(TimeDistributed(\n",
    "#     MaxPooling2D((2,2)))\n",
    "# )\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(TimeDistributed(\n",
    "#     Conv2D(64, (3,3), activation='relu'))\n",
    "# )\n",
    "# model.add(TimeDistributed(\n",
    "#     MaxPooling2D((2,2)))\n",
    "# )\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
    "# model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(GRU(128))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment - 10 Adding dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(TimeDistributed(\n",
    "#     Conv2D(32, (3,3), activation='relu'), input_shape=input_shape)\n",
    "# )\n",
    "# model.add(TimeDistributed(\n",
    "#     MaxPooling2D((2,2)))\n",
    "# )\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(TimeDistributed(\n",
    "#     Conv2D(64, (3,3), activation='relu'))\n",
    "# )\n",
    "# model.add(TimeDistributed(\n",
    "#     MaxPooling2D((2,2)))\n",
    "# )\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
    "# model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(GRU(128))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment - 11  Dense Layer network and Global average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(TimeDistributed(\n",
    "#     Conv2D(32, (3,3), activation='relu'), input_shape=input_shape)\n",
    "# )\n",
    "# model.add(TimeDistributed(\n",
    "#     MaxPooling2D((2,2)))\n",
    "# )\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(TimeDistributed(\n",
    "#     Conv2D(64, (3,3), activation='relu'))\n",
    "# )\n",
    "# model.add(TimeDistributed(\n",
    "#     MaxPooling2D((2,2)))\n",
    "# )\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(TimeDistributed(\n",
    "#     Conv2D(128, (3,3), activation='relu'))\n",
    "# )\n",
    "# model.add(TimeDistributed(\n",
    "#     MaxPooling2D((2,2)))\n",
    "# )\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(GlobalAveragePooling3D())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(5, activation='softmax')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model Convolutional LSTM 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-136d33f2ca27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m model.add(TimeDistributed(\n\u001b[0;32m      3\u001b[0m     Conv2D(8, (3,3), activation='relu'), input_shape=input_shape)\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(TimeDistributed(\n",
    "    Conv2D(8, (3,3), activation='relu'), input_shape=input_shape)\n",
    ")\n",
    "model.add(BatchNormalization())\n",
    "model.add(TimeDistributed(\n",
    "    Conv2D(16, (3,3), activation='relu'))\n",
    ")\n",
    "model.add(BatchNormalization())\n",
    "model.add(\n",
    "    ConvLSTM2D(8, kernel_size = 3, return_sequences=False)\n",
    ")\n",
    "model.add(BatchNormalization())\n",
    "model.add(TimeDistributed(\n",
    "    Dense(64, activation='relu'))\n",
    ")\n",
    "model.add(BatchNormalization())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d3b27c930034>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimiser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#write your optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimiser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'categorical_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optimizers' is not defined"
     ]
    }
   ],
   "source": [
    "optimiser = optimizers.Adam(lr=0.01) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4f0fcddd78a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_doc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maugmention\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menable_augmentation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_doc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size, is_train = True, augmention = enable_augmentation)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'curr_dt_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-8a34f10e43b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'model_init_exp_16'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_dt_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m':'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'curr_dt_time' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init_exp_16' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "\n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "\n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001, verbose=1) # write the REducelronplateau code here\n",
    "\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_train_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-6a0051279329>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_train_sequences\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_train_sequences\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_train_sequences\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_train_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5de157569113>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n\u001b[0m\u001b[0;32m      2\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                         validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                        callbacks=callbacks_list, validation_data=val_generator, \n",
    "                        validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-973121006a43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0max1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m121\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0max1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0max1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAFpCAYAAAC24dPRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQj0lEQVR4nO3dX4jld3nH8c9j1rTU+qc0K5T8MSnd1C5S0A6pRaiKtiS52NxYSUBaS3DBNi20Ukix2BKvqhRBSGu3rVgFjWkv2kVWUrARixjJim0wkcA2WrNEyGptbkTTtE8vZlqmk9md365ndh/2vF4wcH7nfOfMQ77MzDu/c+a31d0BAJjkBZd6AACAnQQKADCOQAEAxhEoAMA4AgUAGEegAADj7BkoVfXhqnq6qr5ylserqj5YVaeq6pGqes3qxwQA1smSMygfSXLzOR6/JcmhrY+jSf7sBx8LAFhnewZKd38uyb+fY8ltST7amx5K8rKq+olVDQgArJ9VvAfl6iRPbjs+vXUfAMAFObCC56hd7tv1+vlVdTSbLwPlRS960c+98pWvXMGXBwAm+tKXvvSt7j54IZ+7ikA5neTabcfXJHlqt4XdfSzJsSTZ2NjokydPruDLAwATVdW/XejnruIlnuNJfnXrr3lem+SZ7v7mCp4XAFhTe55BqapPJHlDkquq6nSSP0zywiTp7g8lOZHk1iSnknw3ya/v17AAwHrYM1C6+449Hu8kv7myiQCAtedKsgDAOAIFABhHoAAA4wgUAGAcgQIAjCNQAIBxBAoAMI5AAQDGESgAwDgCBQAYR6AAAOMIFABgHIECAIwjUACAcQQKADCOQAEAxhEoAMA4AgUAGEegAADjCBQAYByBAgCMI1AAgHEECgAwjkABAMYRKADAOAIFABhHoAAA4wgUAGAcgQIAjCNQAIBxBAoAMI5AAQDGESgAwDgCBQAYR6AAAOMIFABgHIECAIwjUACAcQQKADCOQAEAxhEoAMA4AgUAGEegAADjCBQAYByBAgCMI1AAgHEECgAwjkABAMYRKADAOAIFABhHoAAA4wgUAGAcgQIAjCNQAIBxBAoAMI5AAQDGWRQoVXVzVT1eVaeq6u5dHr+uqh6sqi9X1SNVdevqRwUA1sWegVJVVyS5N8ktSQ4nuaOqDu9Y9gdJ7u/uVye5PcmfrnpQAGB9LDmDclOSU939RHc/m+S+JLftWNNJXrJ1+6VJnlrdiADAujmwYM3VSZ7cdnw6yc/vWPNHSf6hqn4ryYuSvHkl0wEAa2nJGZTa5b7ecXxHko909zVJbk3ysap63nNX1dGqOllVJ8+cOXP+0wIAa2FJoJxOcu2242vy/Jdw7kxyf5J09xeS/HCSq3Y+UXcf6+6N7t44ePDghU0MAFz2lgTKw0kOVdUNVXVlNt8Ee3zHmm8keVOSVNXPZDNQnCIBAC7InoHS3c8luSvJA0m+ms2/1nm0qu6pqiNby96V5B1V9S9JPpHk7d2982UgAIBFlrxJNt19IsmJHfe9Z9vtx5K8brWjAQDrypVkAYBxBAoAMI5AAQDGESgAwDgCBQAYR6AAAOMIFABgHIECAIwjUACAcQQKADCOQAEAxhEoAMA4AgUAGEegAADjCBQAYByBAgCMI1AAgHEECgAwjkABAMYRKADAOAIFABhHoAAA4wgUAGAcgQIAjCNQAIBxBAoAMI5AAQDGESgAwDgCBQAYR6AAAOMIFABgHIECAIwjUACAcQQKADCOQAEAxhEoAMA4AgUAGEegAADjCBQAYByBAgCMI1AAgHEECgAwjkABAMYRKADAOAIFABhHoAAA4wgUAGAcgQIAjCNQAIBxBAoAMI5AAQDGESgAwDgCBQAYR6AAAOMIFABgHIECAIwjUACAcRYFSlXdXFWPV9Wpqrr7LGveWlWPVdWjVfXx1Y4JAKyTA3stqKorktyb5JeSnE7ycFUd7+7Htq05lOT3k7yuu79TVS/fr4EBgMvfkjMoNyU51d1PdPezSe5LctuONe9Icm93fydJuvvp1Y4JAKyTJYFydZIntx2f3rpvuxuT3FhVn6+qh6rq5t2eqKqOVtXJqjp55syZC5sYALjsLQmU2uW+3nF8IMmhJG9IckeSv6yqlz3vk7qPdfdGd28cPHjwfGcFANbEkkA5neTabcfXJHlqlzV/393/2d1fS/J4NoMFAOC8LQmUh5McqqobqurKJLcnOb5jzd8leWOSVNVV2XzJ54lVDgoArI89A6W7n0tyV5IHknw1yf3d/WhV3VNVR7aWPZDk21X1WJIHk/xed397v4YGAC5v1b3z7SQXx8bGRp88efKSfG0AYP9V1Ze6e+NCPteVZAGAcQQKADCOQAEAxhEoAMA4AgUAGEegAADjCBQAYByBAgCMI1AAgHEECgAwjkABAMYRKADAOAIFABhHoAAA4wgUAGAcgQIAjCNQAIBxBAoAMI5AAQDGESgAwDgCBQAYR6AAAOMIFABgHIECAIwjUACAcQQKADCOQAEAxhEoAMA4AgUAGEegAADjCBQAYByBAgCMI1AAgHEECgAwjkABAMYRKADAOAIFABhHoAAA4wgUAGAcgQIAjCNQAIBxBAoAMI5AAQDGESgAwDgCBQAYR6AAAOMIFABgHIECAIwjUACAcQQKADCOQAEAxhEoAMA4AgUAGEegAADjCBQAYByBAgCMsyhQqurmqnq8qk5V1d3nWPeWquqq2ljdiADAutkzUKrqiiT3JrklyeEkd1TV4V3WvTjJbyf54qqHBADWy5IzKDclOdXdT3T3s0nuS3LbLuvem+R9Sb63wvkAgDW0JFCuTvLktuPTW/f9n6p6dZJru/tT53qiqjpaVSer6uSZM2fOe1gAYD0sCZTa5b7+vwerXpDkA0netdcTdfex7t7o7o2DBw8unxIAWCtLAuV0kmu3HV+T5Kltxy9O8qokn62qryd5bZLj3igLAFyoJYHycJJDVXVDVV2Z5PYkx//3we5+pruv6u7ru/v6JA8lOdLdJ/dlYgDgsrdnoHT3c0nuSvJAkq8mub+7H62qe6rqyH4PCACsnwNLFnX3iSQndtz3nrOsfcMPPhYAsM5cSRYAGEegAADjCBQAYByBAgCMI1AAgHEECgAwjkABAMYRKADAOAIFABhHoAAA4wgUAGAcgQIAjCNQAIBxBAoAMI5AAQDGESgAwDgCBQAYR6AAAOMIFABgHIECAIwjUACAcQQKADCOQAEAxhEoAMA4AgUAGEegAADjCBQAYByBAgCMI1AAgHEECgAwjkABAMYRKADAOAIFABhHoAAA4wgUAGAcgQIAjCNQAIBxBAoAMI5AAQDGESgAwDgCBQAYR6AAAOMIFABgHIECAIwjUACAcQQKADCOQAEAxhEoAMA4AgUAGEegAADjCBQAYByBAgCMI1AAgHEECgAwjkABAMYRKADAOIsCpapurqrHq+pUVd29y+O/W1WPVdUjVfWZqnrF6kcFANbFnoFSVVckuTfJLUkOJ7mjqg7vWPblJBvd/bNJ/jbJ+1Y9KACwPpacQbkpyanufqK7n01yX5Lbti/o7ge7+7tbhw8luWa1YwIA62RJoFyd5Mltx6e37jubO5N8+gcZCgBYbwcWrKld7utdF1a9LclGktef5fGjSY4myXXXXbdwRABg3Sw5g3I6ybXbjq9J8tTORVX15iTvTnKku7+/2xN197Hu3ujujYMHD17IvADAGlgSKA8nOVRVN1TVlUluT3J8+4KqenWSP89mnDy9+jEBgHWyZ6B093NJ7kryQJKvJrm/ux+tqnuq6sjWsvcn+dEkf1NV/1xVx8/ydAAAe1ryHpR094kkJ3bc955tt9+84rkAgDXmSrIAwDgCBQAYR6AAAOMIFABgHIECAIwjUACAcQQKADCOQAEAxhEoAMA4AgUAGEegAADjCBQAYByBAgCMI1AAgHEECgAwjkABAMYRKADAOAIFABhHoAAA4wgUAGAcgQIAjCNQAIBxBAoAMI5AAQDGESgAwDgCBQAYR6AAAOMIFABgHIECAIwjUACAcQQKADCOQAEAxhEoAMA4AgUAGEegAADjCBQAYByBAgCMI1AAgHEECgAwjkABAMYRKADAOAIFABhHoAAA4wgUAGAcgQIAjCNQAIBxBAoAMI5AAQDGESgAwDgCBQAYR6AAAOMIFABgHIECAIwjUACAcQQKADCOQAEAxlkUKFV1c1U9XlWnquruXR7/oar65NbjX6yq61c9KACwPvYMlKq6Ism9SW5JcjjJHVV1eMeyO5N8p7t/KskHkvzxqgcFANbHkjMoNyU51d1PdPezSe5LctuONbcl+eut23+b5E1VVasbEwBYJ0sC5eokT247Pr11365ruvu5JM8k+fFVDAgArJ8DC9bsdiakL2BNqupokqNbh9+vqq8s+PpcXFcl+dalHoL/x57MY09msi/z/PSFfuKSQDmd5Nptx9ckeeosa05X1YEkL03y7zufqLuPJTmWJFV1srs3LmRo9o99mceezGNPZrIv81TVyQv93CUv8Tyc5FBV3VBVVya5PcnxHWuOJ/m1rdtvSfKP3f28MygAAEvseQalu5+rqruSPJDkiiQf7u5Hq+qeJCe7+3iSv0rysao6lc0zJ7fv59AAwOVtyUs86e4TSU7suO89225/L8mvnOfXPnae67k47Ms89mQeezKTfZnngvekvBIDAEzjUvcAwDj7Higukz/Pgj353ap6rKoeqarPVNUrLsWc62avfdm27i1V1VXlrxX22ZI9qaq3bn2/PFpVH7/YM66jBT/DrquqB6vqy1s/x269FHOuk6r6cFU9fbbLh9SmD27t2SNV9Zo9n7S79+0jm2+q/dckP5nkyiT/kuTwjjW/keRDW7dvT/LJ/Zxp3T8W7skbk/zI1u132pMZ+7K17sVJPpfkoSQbl3ruy/lj4ffKoSRfTvJjW8cvv9RzX+4fC/flWJJ3bt0+nOTrl3ruy/0jyS8meU2Sr5zl8VuTfDqb1017bZIv7vWc+30GxWXy59lzT7r7we7+7tbhQ9m89g37a8n3SpK8N8n7knzvYg63ppbsyTuS3Nvd30mS7n76Is+4jpbsSyd5ydbtl+b51+5ixbr7c9nl+mfb3Jbko73poSQvq6qfONdz7neguEz+PEv2ZLs7s1m97K8996WqXp3k2u7+1MUcbI0t+V65McmNVfX5qnqoqm6+aNOtryX78kdJ3lZVp7P5F6i/dXFG4xzO93fPsj8z/gGs7DL5rMzi/95V9bYkG0lev68TkeyxL1X1gmz+S+Fvv1gDseh75UA2X+Z5QzbPNP5TVb2qu/9jn2dbZ0v25Y4kH+nuP6mqX8jmdbpe1d3/vf/jcRbn/bt+v8+gnM9l8nOuy+SzMkv2JFX15iTvTnKku79/kWZbZ3vty4uTvCrJZ6vq69l8Dfe4N8ruq6U/v/6+u/+zu7+W5PFsBgv7Z8m+3Jnk/iTp7i8k+eFs/js9XDqLfvdst9+B4jL58+y5J1svJfx5NuPEa+oXxzn3pbuf6e6ruvv67r4+m+8NOtLdF/zvXLCnJT+//i6bbypPVV2VzZd8nrioU66fJfvyjSRvSpKq+plsBsqZizolOx1P8qtbf83z2iTPdPc3z/UJ+/oST7tM/jgL9+T9SX40yd9svV/5G9195JINvQYW7gsX0cI9eSDJL1fVY0n+K8nvdfe3L93Ul7+F+/KuJH9RVb+TzZcR3u5/fPdXVX0imy91XrX13p8/TPLCJOnuD2XzvUC3JjmV5LtJfn3P57RnAMA0riQLAIwjUACAcQQKADCOQAEAxhEoAMA4AgUAGEegAADjCBQAYJz/AaQ2dCVG+q/pAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "ax1 = plt.subplot(121)\n",
    "ax1 = plt.plot(history.history['loss'])\n",
    "ax1 = plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower left')\n",
    "ax2 = plt.subplot(122)\n",
    "ax2 = plt.plot(history.history['categorical_accuracy'])\n",
    "ax2 = plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('categorical_accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
